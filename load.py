import os
import json
from google.cloud import bigquery
from google.cloud import storage

# Charger les variables d'environnement pour rendre le script adaptable
PROJECT_ID = os.getenv("GCP_PROJECT_ID", "your_project_id")
DATASET_NAME = os.getenv("BIGQUERY_DATASET", "your_dataset")
TABLE_NAME = os.getenv("BIGQUERY_TABLE", "your_table")
GCS_TRIGGER_KEYWORD = os.getenv("GCS_TRIGGER_KEYWORD", "stock_data")  # Mot-cl√© pour filtrer les fichiers

def load_csv_to_bigquery(event, context):
    """
    Fonction pour charger un fichier CSV depuis Google Cloud Storage vers BigQuery.
    Cette fonction est d√©clench√©e automatiquement lorsqu'un fichier est ajout√© dans un bucket GCS.
    """
    client = bigquery.Client()
    storage_client = storage.Client()

    # R√©cup√©ration des informations du fichier d√©clencheur
    bucket_name = event['bucket']
    file_name = event['name']
    
    # V√©rifier que le fichier correspond aux crit√®res d√©finis (mot-cl√© dans le nom)
    if GCS_TRIGGER_KEYWORD not in file_name:
        print(f"Le fichier {file_name} ne correspond pas aux crit√®res (mot-cl√© '{GCS_TRIGGER_KEYWORD}' absent).")
        return
    
    uri = f'gs://{bucket_name}/{file_name}'
    table_id = f'{PROJECT_ID}.{DATASET_NAME}.{TABLE_NAME}'

    # Configuration du job de chargement
    job_config = bigquery.LoadJobConfig(
        source_format=bigquery.SourceFormat.CSV,
        skip_leading_rows=1,  # Ignorer l'en-t√™te du fichier CSV
        autodetect=True,  # D√©tection automatique du sch√©ma
        write_disposition=bigquery.WriteDisposition.WRITE_APPEND  # Ajouter les nouvelles donn√©es √† la table existante
    )
    
    # Ex√©cuter le chargement vers BigQuery
    print(f"Chargement en cours depuis {uri} vers {table_id}...")
    load_job = client.load_table_from_uri(uri, table_id, job_config=job_config)
    load_job.result()  # Attendre la fin du job

    print(f"{load_job.output_rows} lignes charg√©es avec succ√®s dans {table_id}.")

    # Optionnel : Supprimer le fichier apr√®s chargement
    # DELETE_AFTER_LOAD = os.getenv("DELETE_AFTER_LOAD", "False").lower() == "true"
    # if DELETE_AFTER_LOAD:
    #     bucket = storage_client.bucket(bucket_name)
    #     blob = bucket.blob(file_name)
    #     blob.delete()
    #     print(f"üóëFichier {file_name} supprim√© du bucket {bucket_name} apr√®s chargement.")
